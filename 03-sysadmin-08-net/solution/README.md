# Домашняя работа по занятию "3.8. Компьютерные сети, лекция 3"

> 1. ipvs. Если при запросе на VIP сделать подряд несколько запросов (например, `for i in {1..50}; do curl -I -s 172.28.128.200>/dev/null; done `), ответы будут получены почти мгновенно. Тем не менее, в выводе `ipvsadm -Ln` еще некоторое время будут висеть активные `InActConn`. Почему так происходит?

 В режиме direct routing у директора нет полной информации о TCP-соединении, т.к. возвратный трафик идёт от real-сервера напрямую клиенту, без захода на директор. Таким образом, если real-сервер 
решит разорвать соединение, у директора может быть об этом только косвенная информация - или поймает FIN/ACK от клиента, или не увидит никакого трафика в течение долгого времени, согласно своей таблице таймаутов. Таким образом, уже закрытое соединение будет висеть в `InActConn`, пока не сбросится по таймауту ipvs.

---
> 2. На лекции мы познакомились отдельно с ipvs и отдельно с keepalived. Воспользовавшись этими знаниями, совместите технологии вместе (VIP должен подниматься демоном keepalived). Приложите конфигурационные файлы, которые у вас получились, и продемонстрируйте работу получившейся конструкции. Используйте для директора отдельный хост, не совмещая его с риалом! Подобная схема возможна, но выходит за рамки рассмотренного на лекции.

Для отказоустойчивой схемы будем использовать 2 real сервера, и два директора-балансера c keepalived и ipvs, чтобы наша схема пережила выход из строя любого из real-серверов или директора.  И ещё отдельный хост в качестве клиента.
Создадим нашу лабу [таким вот Vagrantfile](Vagrantfile). 

- На real-серверах пропишем VIP-адрес на `lo` интерфейсах, и изменим для них поведение ответов на ARP запросы:

```yaml
# cat /etc/netplan/50-vip-lo.yaml
---
network:
  version: 2
  renderer: networkd
  ethernets:
    lo:
      addresses:
      - 172.28.128.210/32
```
```
# cat /etc/sysctl.d/ipvs_real.conf 
net.ipv4.conf.all.arp_ignore=1
net.ipv4.conf.all.arp_announce=2
```
Кроме того, изменим вид отдаваемой nginx странички, чтобы сразу было видно, с какого сервера она пришла, и с каким таймстампом: 
```
location / {
    return 200 'I am Real-1 ($time_local)\n';
}
```

- на директорах установим ipvsadm, keepalived. VIP-адрес будет подниматься самим keepalived.
```
$ cat /etc/keepalived/keepalived.conf 
vrrp_instance VI_1 {
	state BACKUP
	interface eth1
	virtual_router_id 210
	priority 1
	advert_int 1
	authentication {
		auth_type PASS
		auth_pass PassW0rD
	}
	virtual_ipaddress {
		172.28.128.210/24 dev eth1
	}
}
```
Настройки ipvs:
```
$ cat /etc/ipvsadm.rules 
-A -t 172.28.128.210:80 -s rr
-a -t 172.28.128.210:80 -r 172.28.128.40:80 -g -w 1
-a -t 172.28.128.210:80 -r 172.28.128.50:80 -g -w 1
```
```
$ cat /etc/default/ipvsadm |grep "^[A-Z]"
AUTO="true"
DAEMON="none"
IFACE="eth1"	
```

Тут ещё такая проблемка, директор никак не видит, живой real сервер или нет, и поэтому продолжает пересылать на сдохший пользовательские запросы. Чтобы клиенты не страдали, сделаем маленький мониторящий сервис, который будет удалять сбойный real-сервер из ipvs, и добавлять его обратно когда он починится:
```shell
# cat /usr/local/bin/check-reals 
#! /bin/bash

VIP=172.28.128.210
REALS="172.28.128.40 172.28.128.50"
PORT=80

while true; do
	for R in $REALS; do
		if curl --connect-timeout 0.1 -I -s $R >/dev/null ; then
			ipvsadm -Ln |grep -q --  "-> ${R}:" || ipvsadm -a -t ${VIP}:${PORT} -r ${R}:${PORT} -g -w 1
		else
			ipvsadm -Ln |grep -q --  "-> ${R}:" && ipvsadm -d -t ${VIP}:${PORT} -r ${R}:${PORT}
		fi
	done
	sleep 2
done
```
И unit-файл для него:
```
$ cat /etc/systemd/system/check-reals.service 
[Unit]
Description=Check real servers availability
After=ipvsadm.service

[Service]
Type=simple
ExecStart=/usr/local/bin/check-reals
Restart=always

[Install]
WantedBy=multi-user.target
```

Попробуем запустить эту схему и проверить с клиента:
```
$ while true; do curl -m 1 -s 172.28.128.210:80 ; sleep 1; done
I am Real-1 (10/May/2021:18:54:42 +0000)
I am Real-2 (10/May/2021:18:54:43 +0000)
I am Real-1 (10/May/2021:18:54:44 +0000)
I am Real-2 (10/May/2021:18:54:45 +0000)
I am Real-1 (10/May/2021:18:54:46 +0000)
I am Real-2 (10/May/2021:18:54:47 +0000)
^C
```
Замечательно, балансировка есть. Попробуем ребутнуть текущий активный директор:
```
~$ while true; do curl -m 1 -s 172.28.128.210:80 ; sleep 1; done
I am Real-1 (10/May/2021:18:56:09 +0000)
I am Real-2 (10/May/2021:18:56:10 +0000)
I am Real-1 (10/May/2021:18:56:11 +0000)  <----
I am Real-2 (10/May/2021:18:56:14 +0000)  <----
I am Real-1 (10/May/2021:18:56:15 +0000)
I am Real-2 (10/May/2021:18:56:16 +0000)
I am Real-1 (10/May/2021:18:56:17 +0000)
```
У нас был небольшой таймаут в пару секунд, но будем считать, клиент ничего не успел заметить :)

Попробуем ребутнуть один из real-серверов:
```
$ while true; do curl -m 1 -s 172.28.128.210:80 ; sleep 1; done
I am Real-2 (10/May/2021:18:58:41 +0000)
I am Real-1 (10/May/2021:18:58:42 +0000)
I am Real-2 (10/May/2021:18:58:43 +0000)
I am Real-1 (10/May/2021:18:58:44 +0000)
I am Real-1 (10/May/2021:18:58:45 +0000)
I am Real-1 (10/May/2021:18:58:46 +0000)
I am Real-1 (10/May/2021:18:58:47 +0000)
I am Real-1 (10/May/2021:18:58:48 +0000)
I am Real-1 (10/May/2021:18:58:49 +0000)
I am Real-1 (10/May/2021:18:58:50 +0000)
I am Real-1 (10/May/2021:18:58:51 +0000)
I am Real-1 (10/May/2021:18:58:52 +0000)
I am Real-2 (10/May/2021:18:58:54 +0000)
I am Real-1 (10/May/2021:18:58:54 +0000)
I am Real-2 (10/May/2021:18:58:56 +0000)
```
Гладенько, плавненько.

---
> 3. В лекции мы использовали только 1 VIP адрес для балансировки.
У такого подхода несколько отрицательных моментов, один из которых – невозможность активного использования нескольких хостов (1 адрес может только переехать с master на standby). 
Подумайте, сколько адресов оптимально использовать, если мы хотим без какой-либо деградации выдерживать потерю 
1 из 3 хостов при входящем трафике 1.5 Гбит/с и физических линках хостов в 1 Гбит/с? Предполагается, что мы хотим задействовать 3 балансировщика в активном режиме 
(то есть не 2 адреса на 3 хоста, один из которых в обычное время простаивает).

Мы могли бы использовать 3 VIP адреса, по одному на хосту. На каждый приходит 1.5 / 3 = 0.5Гбит/с, в мирное время всё замечательно. Но при отказе какого-нибудь хоста на его standby 
вдруг придёт весь трафик с умершего мастера, что с сумме с его собственным (0.5 + 0.5) упрётся в пропускную способность его физического линка, могут начаться потери пакетов, может страдать 
management, heartbeat и прочий служебный трафик, в общем, лучше избежать.  
Более предпочтительным выглядит конфигурировать на каждом хосте по 2 VIP адреса, с настройкой их standby на разных хостах. 
Тогда на каждый VIP у нас будет приходить примерно по 0.25Гбит/с, и, в случае аварии одного хоста, его трафик перераспределится поровну на два других, что составит для каждого:
0.25*2 (его собственного) + 0.25 со сбойного. 0.75 в сумме, вполне терпимо.



 
